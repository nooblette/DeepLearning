{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShuffleNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5sH7TbPpyMcXRELhp3Qge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nooblette/DeepLearning/blob/main/ShuffleNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO-4QD1wn87t",
        "outputId": "5a482f1f-31d1-4e10-d216-8d188feede6d"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize\n",
        "                                transforms.Resize((32, 32))\n",
        "                                ])\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train = True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train = False, transform=transform, download=True)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ShuffleBlock(nn.Module):\n",
        "    def __init__(self, groups):\n",
        "        super(ShuffleBlock, self).__init__()\n",
        "        self.groups = groups\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]'''\n",
        "        N,C,H,W = x.size()\n",
        "        g = self.groups\n",
        "        return x.view(N,g,C//g,H,W).permute(0,2,1,3,4).reshape(N,C,H,W)\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, groups):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        mid_planes = out_planes//4\n",
        "        g = 1 if in_planes==24 else groups\n",
        "        self.conv1 = nn.Conv2d(in_planes, mid_planes, kernel_size=1, groups=g, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_planes)\n",
        "        self.shuffle1 = ShuffleBlock(groups=g)\n",
        "        self.conv2 = nn.Conv2d(mid_planes, mid_planes, kernel_size=3, \n",
        "                               stride=stride, padding=1, groups=mid_planes, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_planes)\n",
        "        self.conv3 = nn.Conv2d(mid_planes, out_planes, kernel_size=1, groups=groups, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 2:\n",
        "            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.shuffle1(out)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        res = self.shortcut(x)\n",
        "        out = F.relu(torch.cat([out,res], 1)) if self.stride==2 else F.relu(out+res)\n",
        "        return out\n",
        "\n",
        "class ShuffleNet(nn.Module):\n",
        "    cfg = {'out_planes': [200, 400, 800], 'num_blocks': [4,8,4], 'groups': 2}\n",
        "    def __init__(self):\n",
        "        super(ShuffleNet, self).__init__()\n",
        "        out_planes = ShuffleNet.cfg['out_planes']\n",
        "        num_blocks = ShuffleNet.cfg['num_blocks']\n",
        "        groups = ShuffleNet.cfg['groups']\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(24)\n",
        "        self.in_planes = 24\n",
        "        self.layer1 = self._make_layer(out_planes[0], num_blocks[0], groups)\n",
        "        self.layer2 = self._make_layer(out_planes[1], num_blocks[1], groups)\n",
        "        self.layer3 = self._make_layer(out_planes[2], num_blocks[2], groups)\n",
        "        self.linear = nn.Linear(out_planes[2], 10)\n",
        "\n",
        "    def _make_layer(self, out_planes, num_blocks, groups):\n",
        "        layers = []\n",
        "        for i in range(num_blocks):\n",
        "            stride = 2 if i == 0 else 1\n",
        "            cat_planes = self.in_planes if i == 0 else 0\n",
        "            layers.append(Bottleneck(self.in_planes, out_planes-cat_planes, stride=stride, groups=groups))\n",
        "            self.in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def accuracy(y, label, printable=False):\n",
        "      with torch.no_grad():\n",
        "        pred = torch.argmax(y.data, 1)\n",
        "        correct = (pred==label).sum().item()\n",
        "        temp_acc = (100*correct / y.shape[0])\n",
        "        if printable:\n",
        "          print(f'Accuracy of the network on the test images (batch_size : {y.shape[0]}): {temp_acc}%')\n",
        "        return temp_acc\n",
        "        \n",
        "def train():\n",
        "    # summary(shuffleNet, input_size=(3, 32, 32), batch_size=batch_size, device=device)\n",
        "\n",
        "    max_epoch = 10\n",
        "    for epoch in range(max_epoch):\n",
        "      total_acc = []\n",
        "      total_loss = []\n",
        "      start_time = time.time()\n",
        "      print(f\"Epoch {epoch} starts.\")\n",
        "\n",
        "      for data, label in tqdm.tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y = shuffleNet(data)\n",
        "\n",
        "        temp_acc = accuracy(y, label, printable = False)\n",
        "        total_acc.append(temp_acc)\n",
        "\n",
        "        loss = CEloss(y, label)\n",
        "        total_loss.append(loss)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(f\"{epoch} epoch loss : {np.array(total_loss).sum() / len(total_loss)}\")\n",
        "      print(f\"{epoch} epoch accuracy : {np.array(total_acc).sum() / len(total_acc)}\")\n",
        "      print(f\"{epoch} epoch time : {time.time() - start_time } (s)\")\n",
        "      print(\"\\n\")\n",
        "\n",
        "def test():\n",
        "    start_time = time.time()\n",
        "\n",
        "    total_acc = []\n",
        "    total_loss = []\n",
        "\n",
        "    for data, label in tqdm.tqdm(test_loader):\n",
        "      with torch.no_grad():\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        y = shuffleNet(data)\n",
        "\n",
        "        temp_acc = accuracy(y, label)\n",
        "        total_acc.append(temp_acc)\n",
        "\n",
        "        loss = CEloss(y, label)\n",
        "        total_loss.append(loss)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(f\"Test loss ; {np.array(total_loss).sum() / len(total_loss)}\")\n",
        "    print(f\"Test train accuracy : {np.array(total_acc).sum() / len(total_acc)}\")\n",
        "    print(f\"Single epoch Time : {time.time() - start_time} (s)\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "shuffleNet = ShuffleNet().to(device)\n",
        "CEloss = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(shuffleNet.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "train()\n",
        "test()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:06<00:00,  6.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "0 epoch loss : 1.9499588012695312\n",
            "0 epoch accuracy : 33.182397959183675\n",
            "0 epoch time : 1326.5453009605408 (s)\n",
            "\n",
            "\n",
            "Epoch 1 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:08<00:00,  6.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1 epoch loss : 1.4620800018310547\n",
            "1 epoch accuracy : 48.704958545918366\n",
            "1 epoch time : 1328.8966012001038 (s)\n",
            "\n",
            "\n",
            "Epoch 2 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [21:59<00:00,  6.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "2 epoch loss : 1.2048498392105103\n",
            "2 epoch accuracy : 57.11734693877551\n",
            "2 epoch time : 1319.2097301483154 (s)\n",
            "\n",
            "\n",
            "Epoch 3 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:16<00:00,  6.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "3 epoch loss : 1.083083152770996\n",
            "3 epoch accuracy : 62.0344387755102\n",
            "3 epoch time : 1336.7220633029938 (s)\n",
            "\n",
            "\n",
            "Epoch 4 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:08<00:00,  6.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "4 epoch loss : 0.9734275341033936\n",
            "4 epoch accuracy : 65.89405293367346\n",
            "4 epoch time : 1328.2540402412415 (s)\n",
            "\n",
            "\n",
            "Epoch 5 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [21:54<00:00,  6.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "5 epoch loss : 0.8989843130111694\n",
            "5 epoch accuracy : 68.41119260204081\n",
            "5 epoch time : 1314.2624323368073 (s)\n",
            "\n",
            "\n",
            "Epoch 6 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:25<00:00,  6.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "6 epoch loss : 0.8184847831726074\n",
            "6 epoch accuracy : 71.3719706632653\n",
            "6 epoch time : 1345.2457571029663 (s)\n",
            "\n",
            "\n",
            "Epoch 7 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:05<00:00,  6.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "7 epoch loss : 0.7149566411972046\n",
            "7 epoch accuracy : 75.0015943877551\n",
            "7 epoch time : 1325.8969197273254 (s)\n",
            "\n",
            "\n",
            "Epoch 8 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [22:19<00:00,  6.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "8 epoch loss : 0.6474006772041321\n",
            "8 epoch accuracy : 77.1727519132653\n",
            "8 epoch time : 1339.5041732788086 (s)\n",
            "\n",
            "\n",
            "Epoch 9 starts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [21:54<00:00,  6.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "9 epoch loss : 0.6040862202644348\n",
            "9 epoch accuracy : 78.55907206632654\n",
            "9 epoch time : 1314.2175059318542 (s)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [01:33<00:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test loss ; 0.9601673126220703\n",
            "Test train accuracy : 69.560546875\n",
            "Single epoch Time : 93.0175895690918 (s)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}